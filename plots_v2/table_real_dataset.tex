\begin{table}
    \footnotesize
    \centering
    \caption{}
    \begin{tabular}{c|c|c|c}
        \toprule
        $y_i$ & $y'_i$ & $|y'_i-y_i|$ & $\lambda$ \\
        \midrule
        0 & 0 & 0 & 1 \\
        0 & 1 & 1 & 1 \\
        1 & 0 & -1 & -1 \\
        1 & 1 & 0 & -1 \\
        \bottomrule
    \end{tabular}
    \label{table.y}
\end{table}


\begin{table}[t!]
    \footnotesize
    \centering
    \caption{Summary of the datasets' training set size ($n$), number of features ($m$), Positive Label Rate (PLR) and the average accuracy (\%) for train and test sets across all classifiers on the same dataset.}
    \begin{tabular}{l|r|r|r|r|r}
        \toprule
        Dataset      & $n$  & $m$ & PLR  & Train & Test \\
        \midrule
        Abalone      & 1600 & 7   & 0.50 & $79.9\pm0.7$ &  $76.5\pm0.5$ \\
        Australian   & 552  & 14  & 0.45 & $91.5\pm3.1$ &  $81.9\pm2.1$ \\
        Banknote     & 1097 & 4   & 0.44 & $100.0\pm0.0$ & $100.0\pm0.0$ \\
        Breastcancer & 455  & 30  & 0.63 & $99.3\pm0.2$ &  $95.0\pm2.5$ \\
        CMC          & 1178 & 9   & 0.77 & $79.9\pm2.8$ &  $77.5\pm0.6$ \\
        HTRU2        & 1600 & 8   & 0.50 & $94.8\pm0.5$ &  $92.6\pm0.9$ \\
        Phoneme      & 1600 & 5   & 0.50 & $89.7\pm6.3$ &  $85.6\pm1.3$ \\
        Ringnorm     & 1600 & 20  & 0.50 & $99.4\pm0.4$ &  $97.8\pm1.1$ \\
        Texture      & 800  & 40  & 0.50 & $100.0\pm0.0$ &  $99.8\pm0.5$ \\
        Yeast        & 713  & 8   & 0.48 & $73.5\pm4.7$ &  $65.8\pm1.6$ \\
        \bottomrule
    \end{tabular}
    \label{tab.datasets}
\end{table}


\begin{table}
    \footnotesize
    \centering
    \caption{
        Performance loss (\%) after attacked by a poisoning attack with 30\% poisoning rate. 
        This is the test accuracy difference before and after the attack. 
        If we consider 10\% performance loss is significant at 30\% poisoning rate, then 1 on SLN and 2 classifier on PoisSVM have significant degradation. 
        Meanwhile, all classifiers attacked by ALFA and FALFA have significant degradation.
    }
    \begin{tabular}{l|r|r|r|r}
        \toprule
        Dataset &         Rand &      PoisSVM &          ALFA &         FALFA \\
    \midrule
        Abalone &  $1.9\pm1.9$ &  $3.1\pm1.7$ &  $\bm{28.8\pm2.6}$ &  $\bm{22.5\pm3.7}$ \\
        Australian &  $2.9\pm2.9$ & $\bm{12.8\pm7.7}$ & $\bm{37.5\pm13.1}$ & $\bm{31.6\pm10.9}$ \\
        Banknote &  $6.9\pm6.1$ &  $3.6\pm1.8$ &  $\bm{30.5\pm4.3}$ &  $\bm{33.5\pm4.6}$ \\
    Breastcancer &  $8.6\pm4.2$ &  $9.6\pm4.8$ &  $\bm{30.0\pm7.5}$ &  $\bm{31.6\pm2.8}$ \\
            CMC &  $0.9\pm1.7$ & $\bm{18.0\pm5.2}$ & $\bm{28.9\pm14.8}$ &  $\bm{20.7\pm3.5}$ \\
            HTRU2 &  $2.4\pm0.6$ &  $2.5\pm1.2$ &  $\bm{31.0\pm3.3}$ &  $\bm{30.8\pm3.6}$ \\
        Phoneme & $\bm{15.0\pm4.4}$ &  $4.7\pm1.4$ &  $\bm{24.0\pm2.5}$ &  $\bm{28.8\pm1.4}$ \\
        Ringnorm &  $5.9\pm6.9$ &  $5.0\pm1.1$ &  $\bm{44.1\pm3.8}$ &  $\bm{32.7\pm1.9}$ \\
        Texture &  $4.5\pm8.0$ &  $3.0\pm1.9$ &  $\bm{35.1\pm3.0}$ &  $\bm{34.7\pm2.1}$ \\
            Yeast &  $3.2\pm4.3$ &  $6.6\pm7.3$ &  $\bm{19.7\pm3.7}$ &  $\bm{13.6\pm2.6}$ \\
    \bottomrule
    \end{tabular}
    \label{tab.err}
\end{table}


\begin{table}[t!]
    \footnotesize
    \centering
    \caption{Root Mean Square Error (RMSE) of DIVA estimates clean test accuracy when trained on FALFA and SLN. 
    The prediction with smallest error in the same dataset is highlighted.
    The RMSEs on unknown attacks (PoisSVM, ALFA) are comparable to known attacks (SLN, FALFA), but with higher SDs.}
    \begin{tabular}{l|rr|rr}
        \toprule
        Dataset &   SLN &  FALFA &  PoisSVM &  ALFA \\
        \midrule                                             
            Abalone        & 0.072      &  0.083      &    \textbf{0.058} & 0.115 \\
            Australian     & 0.072      &  0.110      &    \textbf{0.065} & 0.115 \\
            Banknote       & 0.126      &  0.145      &    0.175 & \textbf{0.089} \\
            Breastcancer   & 0.068      &  0.114      &    \textbf{0.066} & 0.116 \\
            CMC            & \textbf{0.102}      &  0.208      &    0.250 & 0.250 \\
            HTRU2          & \textbf{0.055}      &  0.094      &    0.061 & 0.106 \\
            Phoneme        & 0.087      &  0.094      &    \textbf{0.067} & 0.085 \\
            Ringnorm       & 0.192      &  \textbf{0.135}      &    0.149 & 0.140 \\
            Texture        & 0.091      &  0.073      &    0.099 & \textbf{0.067} \\
            Yeast          & \textbf{0.084}    &  0.125        &    0.092 & 0.186 \\
        \midrule
        \textbf{Mean} & $\bm{0.095\pm0.039}$ & $\bm{0.108\pm0.039}$ & $\bm{0.127\pm0.064}$ & $\bm{0.118\pm0.054}$ \\
        \bottomrule
        \end{tabular}
    \label{table.real_rmse}
\end{table}


\begin{tabular}{lllll}
    \toprule
         Dataset &         Rand &      PoisSVM &         ALFA &        FALFA \\
    \midrule
         Abalone &  $0.8\pm0.7$ &  $1.8\pm0.8$ &  $9.5\pm1.9$ &  $7.7\pm1.7$ \\
      Australian &  $0.7\pm0.5$ &  $4.5\pm3.9$ &  $4.9\pm4.0$ &  $8.3\pm3.8$ \\
        Banknote &  $1.4\pm2.3$ &  $1.1\pm1.1$ & $10.9\pm2.5$ & $10.3\pm2.9$ \\
    Breastcancer &  $2.5\pm0.7$ &  $5.3\pm4.6$ &  $7.2\pm2.0$ &  $9.1\pm2.7$ \\
             CMC & $-0.2\pm0.7$ & $15.1\pm4.7$ &  $3.5\pm3.0$ &  $5.7\pm3.3$ \\
           HTRU2 &  $0.7\pm0.3$ &  $0.7\pm1.3$ &  $9.2\pm3.1$ &  $9.4\pm2.4$ \\
         Phoneme &  $3.5\pm2.9$ &  $0.9\pm2.1$ &  $6.8\pm0.7$ & $11.6\pm2.1$ \\
        Ringnorm &  $0.1\pm0.3$ &  $1.7\pm0.5$ &  $3.2\pm2.5$ &  $6.4\pm2.9$ \\
         Texture &  $0.5\pm1.1$ &  $1.2\pm0.8$ &  $7.9\pm4.6$ &  $4.9\pm3.9$ \\
           Yeast & $-0.2\pm1.6$ &  $1.9\pm3.8$ & $10.4\pm4.9$ &  $2.3\pm4.6$ \\
    \bottomrule
\end{tabular}


\begin{table}
    \footnotesize
    \centering
    \caption{}
    \begin{tabular}{l|r|r|r|r}
        \toprule
             Dataset &         Rand &      PoisSVM &         ALFA &        FALFA \\
        \midrule
             Abalone &  $0.8\pm0.7$ &  $1.8\pm0.8$ &  $9.5\pm1.9$ &  $7.7\pm1.7$ \\
          Australian &  $0.7\pm0.5$ &  $4.5\pm3.9$ &  $4.9\pm4.0$ &  $8.3\pm3.8$ \\
            Banknote &  $1.4\pm2.3$ &  $1.1\pm1.1$ & $10.9\pm2.5$ & $10.3\pm2.9$ \\
        Breastcancer &  $2.5\pm0.7$ &  $5.3\pm4.6$ &  $7.2\pm2.0$ &  $9.1\pm2.7$ \\
                 CMC & $-0.2\pm0.7$ & $15.1\pm4.7$ &  $3.5\pm3.0$ &  $5.7\pm3.3$ \\
               HTRU2 &  $0.7\pm0.3$ &  $0.7\pm1.3$ &  $9.2\pm3.1$ &  $9.4\pm2.4$ \\
             Phoneme &  $3.5\pm2.9$ &  $0.9\pm2.1$ &  $6.8\pm0.7$ & $11.6\pm2.1$ \\
            Ringnorm &  $0.1\pm0.3$ &  $1.7\pm0.5$ &  $3.2\pm2.5$ &  $6.4\pm2.9$ \\
             Texture &  $0.5\pm1.1$ &  $1.2\pm0.8$ &  $7.9\pm4.6$ &  $4.9\pm3.9$ \\
               Yeast & $-0.2\pm1.6$ &  $1.9\pm3.8$ & $10.4\pm4.9$ &  $2.3\pm4.6$ \\
        \bottomrule
    \end{tabular}
    \label{}
\end{table}


\begin{table}[t!]
    \footnotesize
    \centering
    \caption{Summary of the datasets' training set size ($n$), number of features ($m$), Positive Label Rate (PLR), the average accuracy (\%) for train and test sets across all classifiers on the same dataset, and their difficulty (\underline{E}asy/\underline{N}ormal/\underline{H}ard). 
    }
    \begin{tabular}{l|r|r|r|r|r|c}
        \toprule
        Dataset      & $n$  & $m$ & PLR  & Train Acc. & Test Acc. & Diff. \\
        \midrule                                                                 
        Abalone      & 1600 & 7   & 0.50 & $79.9\pm0.7$ &  $76.5\pm0.5$     & N \\
        Australian   & 552  & 14  & 0.45 & $91.5\pm3.1$ &  $81.9\pm2.1$     & N \\
        Banknote     & 1097 & 4   & 0.44 & $100.0\pm0.0$ & $100.0\pm0.0$    & E \\
        Breastcancer & 455  & 30  & 0.63 & $99.3\pm0.2$ &  $95.0\pm2.5$     & E \\
        CMC          & 1178 & 9   & 0.77 & $79.9\pm2.8$ &  $77.5\pm0.6$     & N \\
        HTRU2        & 1600 & 8   & 0.50 & $94.8\pm0.5$ &  $92.6\pm0.9$     & E \\
        Phoneme      & 1600 & 5   & 0.50 & $89.7\pm6.3$ &  $85.6\pm1.3$     & N \\
        Ringnorm     & 1600 & 20  & 0.50 & $99.4\pm0.4$ &  $97.8\pm1.1$     & E \\
        Texture      & 800  & 40  & 0.50 & $100.0\pm0.0$ &  $99.8\pm0.5$    & E \\
        Yeast        & 713  & 8   & 0.48 & $73.5\pm4.7$ &  $65.8\pm1.6$     & H \\
        \bottomrule
    \end{tabular}
    \label{tab.datasets}
\end{table}


\begin{table}[t!]
    \footnotesize
    \centering
    \caption{List of measures in C-Measures. If possible, Standard Deviations (SDs) of measures are also included, but are not listed.}
    \begin{tabular}{l|c|p{5cm}}
    \toprule
    Category & Acronym & Description \\ 
    \midrule
    \multirow{5}{*}{Feature-based}   & F1     & Maximum Fisher’s discriminant ratio                        \\
                                     & F1v     & Directional-vector maximum Fisher’s discriminant ratio    \\
                                     & F2     & Volume of overlapping region                               \\
                                     & F3     & Maximum individual feature efficiency                      \\
                                     & F4     & Collective feature efficiency                              \\ 
    \midrule
    \multirow{3}{*}{Linearity}       & L1     & Sum of the error distance by linear programming            \\
                                     & L2     & Error rate of the linear SVM classifier                    \\
                                     & L3     & Non-linearity of the linear SVM classifier                 \\
    \midrule
    \multirow{6}{*}{Neighborhood}    & N1     & Fraction of borderline points                              \\
                                     & N2     & Ratio of intra/extra class nearest-neighbors distance      \\
                                     & N3     & Error rate of nearest-neighbors classifier                 \\
                                     & N4     & Non-linearity of nearest-neighbors classifier              \\
                                     & T1     & Fraction of hyperspheres covering data                     \\
                                     & LSC     & Local Set average Cardinality                             \\
    \midrule
    \multirow{3}{*}{Network}         & Density     & Average density of the network                        \\
                                     & ClsCoef     & Clustering Coefficient                                \\
                                     & Hubs     & Hub score -- Number of connections each node has         \\
    \midrule
    \multirow{3}{*}{Dimensionality}  & T2     & Average number of features per dimension                   \\
                                     & T3     & Average number of PCA dimensions per points                \\
                                     & T4     & Ratio of the PCA dimension to the original dimension       \\
    \midrule
    \multirow{2}{*}{Class Imbalance} & C1     & Entropy of classes proportions                             \\
                                     & C2     & Imbalance ratio                                            \\ 
    \bottomrule
    \end{tabular}
    \label{tab.cmeasure}
\end{table}
