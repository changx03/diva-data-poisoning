{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.metrics import RocCurveDisplay, auc, mean_absolute_error, roc_curve\n",
    "\n",
    "from label_flip_revised.utils import create_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_ROOT = Path(os.getcwd()).absolute().parent\n",
    "print('Root:', PATH_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_output = os.path.join(PATH_ROOT, 'results_plot')\n",
    "print('Output:', path_output)\n",
    "create_dir(path_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pivot_by_difficulty(df: pd.DataFrame, threshold: float=None) -> pd.DataFrame: \n",
    "    df_ = df[['Difficulty', 'Rate', 'Similarity']]\n",
    "\n",
    "    if threshold is None:\n",
    "        for i in np.arange(0.05, 0.5, 0.01):\n",
    "            threshold = i\n",
    "            results = (1 - df_['Similarity']) >= threshold\n",
    "            df_['Prediction'] = results.astype(int)\n",
    "            # count = df_['Prediction'][(df_['Rate'] == 0) & (df_['Difficulty'] == 'Easy')].sum()\n",
    "            # if count == 0:\n",
    "                # break\n",
    "            count = df_['Prediction'][(df_['Rate'] == 0) & (df_['Difficulty'] == 'Normal')].sum()\n",
    "            if count <= 1:\n",
    "                break\n",
    "    else:\n",
    "        results = (1 - df_['Similarity']) >= threshold\n",
    "        df_['Prediction'] = results.astype(int)\n",
    "    print('Threshold:', threshold)\n",
    "\n",
    "    df_ = df_.rename(columns = {'Difficulty':'Dataset Difficulty', 'Rate':'Poisoning Rate', 'Prediction': 'FPR'})\n",
    "    df_grouped = df_.groupby(['Dataset Difficulty', 'Poisoning Rate']).sum()\n",
    "    df_grouped = df_grouped.reset_index()\n",
    "    df_pivot = df_grouped.pivot('Poisoning Rate', 'Dataset Difficulty', 'FPR')\n",
    "    df_pivot = df_pivot[['Easy', 'Normal', 'Hard']]\n",
    "    return df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [] \n",
    "paths.append(os.path.join(PATH_ROOT, 'results', 'synth', 'baseline', 'synth_alfa_svm_knndefense.csv'))\n",
    "paths.append(os.path.join(PATH_ROOT, 'results', 'synth', 'baseline', 'synth_falfa_nn_knndefense.csv'))\n",
    "\n",
    "# Checking the threshold for each attack\n",
    "for p in paths:\n",
    "    df_ = pd.read_csv(p)\n",
    "    pivot_table = get_pivot_by_difficulty(df_)\n",
    "    print(pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_tables = []\n",
    "threshold = 0.32\n",
    "for att in ['falfa_nn', 'alfa_svm']:\n",
    "    df_ = pd.read_csv(os.path.join(PATH_ROOT, 'results', 'synth', 'baseline', f'synth_{att}_knndefense.csv'))\n",
    "    pivot_table = get_pivot_by_difficulty(df_, threshold)\n",
    "    pivot_table.to_csv(os.path.join(path_output, f'synth_pivot_baseline_difficulty_{att}.csv'))\n",
    "\n",
    "    pivot_table = pivot_table.reset_index()\n",
    "    pivot_tables.append(pivot_table)\n",
    "        \n",
    "pivot_1 = pd.concat(pivot_tables, ignore_index=True).groupby('Poisoning Rate').mean().round()\n",
    "pivot_1 = pivot_1 * 2\n",
    "\n",
    "print(pivot_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pivot_by_noise(df: pd.DataFrame, threshold: float=None) -> pd.DataFrame: \n",
    "    df_ = df[['Noise', 'Rate', 'Similarity']]\n",
    "\n",
    "    if threshold is None:\n",
    "        for i in np.arange(0.05, 0.5, 0.01):\n",
    "            threshold = i\n",
    "            results = (1 - df_['Similarity']) >= threshold\n",
    "            df_['Prediction'] = results.astype(int)\n",
    "\n",
    "            count = df_['Prediction'][(df_['Rate'] == 0) & (df_['Noise'] == 0.)].sum()\n",
    "            if count <= 1:\n",
    "                break\n",
    "    else:\n",
    "        results = (1 - df_['Similarity']) >= threshold\n",
    "        df_['Prediction'] = results.astype(int)\n",
    "    print('Threshold:', threshold)\n",
    "\n",
    "    df_ = df_.rename(columns = {'Noise':'Noise Label Rate', 'Rate':'Poisoning Rate', 'Prediction': 'FPR'})\n",
    "    df_grouped = df_.groupby(['Noise Label Rate', 'Poisoning Rate']).sum()\n",
    "    df_grouped = df_grouped.reset_index()\n",
    "    df_pivot = df_grouped.pivot('Poisoning Rate', 'Noise Label Rate', 'FPR')\n",
    "    return df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [] \n",
    "paths.append(os.path.join(PATH_ROOT, 'results', 'synth_noisy', 'baseline', 'synth_alfa_svm_knndefense.csv'))\n",
    "paths.append(os.path.join(PATH_ROOT, 'results', 'synth_noisy', 'baseline', 'synth_falfa_nn_knndefense.csv'))\n",
    "\n",
    "# Checking the threshold for each attack\n",
    "for p in paths:\n",
    "    df_ = pd.read_csv(p)\n",
    "    pivot_table = get_pivot_by_noise(df_)\n",
    "    print(pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_tables = []\n",
    "threshold = 0.37\n",
    "for att in ['falfa_nn', 'alfa_svm']:\n",
    "    df_ = pd.read_csv(os.path.join(PATH_ROOT, 'results', 'synth_noisy', 'baseline', f'synth_{att}_knndefense.csv'))\n",
    "    pivot_table = get_pivot_by_noise(df_, threshold)\n",
    "    pivot_table.to_csv(os.path.join(path_output, f'synth_pivot_baseline_noisy_{att}.csv'))\n",
    "\n",
    "    pivot_table = pivot_table.reset_index()\n",
    "    pivot_tables.append(pivot_table)\n",
    "        \n",
    "pivot_2 = pd.concat(pivot_tables, ignore_index=True).groupby('Poisoning Rate').mean().round()\n",
    "pivot_2 = pivot_2 * 2\n",
    "\n",
    "print(pivot_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline subfigures at top row\n",
    "# Keep subtitles, but remove X labels\n",
    "\n",
    "FONTSIZE = 13\n",
    "FIGSIZE = (8, 4)\n",
    "# X_LABELS = ['Dataset Difficulty', 'Label Noise Rate']\n",
    "TITLES = ['By Difficulties', 'By Label Noise Rates']\n",
    "\n",
    "plt.rcParams[\"font.size\"] = FONTSIZE\n",
    "fig, axes = plt.subplots(1, 2, sharey=True, figsize=FIGSIZE)\n",
    "\n",
    "sns.heatmap(pivot_1, ax=axes[0], annot=True, fmt='.0f', cmap=\"Greens\", vmin=0, vmax=100, cbar=False)\n",
    "axes[0].set_ylabel('Poisoning Rate', fontsize=FONTSIZE+1)\n",
    "\n",
    "sns.heatmap(pivot_2, ax=axes[1], annot=True, fmt='.0f', cmap=\"Greens\", vmin=0, vmax=100)\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    # ax.set_xlabel(X_LABELS[i], fontsize=FONTSIZE+1)\n",
    "    ax.set(xlabel=None)\n",
    "    ax.set_title(TITLES[i], fontsize=FONTSIZE+2)\n",
    "\n",
    "plt.tight_layout(pad=0.6)\n",
    "plot_heatmap = os.path.join(path_output, 'synth_heatmap_baseline.svg')\n",
    "plt.savefig(plot_heatmap, dpi=300)\n",
    "print(f'Save to: {plot_heatmap}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14a78747280fbbbcd2c216d7ac55361a92dd2b0925fb158d072af80087748cfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
