{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from numpy.core.defchararray import find\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from scipy import stats\n",
    "from sklearn import linear_model, preprocessing\n",
    "from sklearn.metrics import (RocCurveDisplay, auc, confusion_matrix,\n",
    "                             mean_squared_error, roc_curve)\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from label_flip_revised.simple_nn_model import SimpleModel\n",
    "from label_flip_revised.torch_utils import evaluate, train_model\n",
    "from label_flip_revised.utils import create_dir, open_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_ROOT = Path(os.getcwd()).absolute().parent\n",
    "print(PATH_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cm = sorted(glob(os.path.join(PATH_ROOT, 'results', 'synth_rand', '*.csv')))\n",
    "print(len(path_cm))\n",
    "print(path_cm[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame()\n",
    "for p in path_cm:\n",
    "    _df = pd.read_csv(p)\n",
    "    df_cm = pd.concat([df_cm, _df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add rates\n",
    "rates = [float(Path(d).stem.split('_')[-1]) for d in df_cm['Data'].to_list()]\n",
    "df_cm['Rate'] = rates\n",
    "df_cm = df_cm[df_cm['Rate'] <= 0.41]\n",
    "print(df_cm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add filepath\n",
    "df_cm['Filepath'] = df_cm['Data'].apply(lambda x: os.path.join('data', 'synth', 'rand', x))\n",
    "df_cm['Data'] = df_cm['Data'].apply(lambda x: x[:-len('_random_0.05.csv')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clean = sorted(glob(os.path.join(PATH_ROOT, 'results', 'synth_svm', '*clean*')))\n",
    "df_cm_clean = pd.DataFrame()\n",
    "for p in path_clean:\n",
    "    _df = pd.read_csv(p)\n",
    "    df_cm_clean = pd.concat([df_cm_clean, _df], ignore_index=True)\n",
    "\n",
    "df_cm_clean['Rate'] = 0\n",
    "df_cm_clean['Filepath'] = df_cm_clean['Data'].apply(lambda x: os.path.join('data', 'synth', 'train', '{}_clean_train.csv'.format(x.split('.')[0])))\n",
    "df_cm_clean['Data'] = df_cm_clean['Data'].apply(lambda x: x.split('.')[0])\n",
    "\n",
    "df_cm = pd.concat([df_cm_clean, df_cm], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NA\n",
    "print('# of columns before removing NA:', len(df_cm.columns) - 1)  # Name does not count\n",
    "cols_not_na = df_cm.columns[df_cm.notna().any()].tolist()\n",
    "df_cm = df_cm[cols_not_na]\n",
    "print('# of columns after removing NA:', len(df_cm.columns) - 1)  # Name does not count\n",
    "print(cols_not_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = df_cm.sort_values(by=['Data', 'Rate'], ignore_index=True)\n",
    "df_cm['Testpath'] = df_cm['Data'].apply(lambda x: os.path.join('data', 'synth', 'test', f'{x}_clean_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm['Train'] = 0.\n",
    "df_cm['Test'] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_NAMES = ['Data', 'F1', 'F1 SD', 'F1v', 'F2', 'F3', 'F4', 'N1', \n",
    "    'N2', 'N2 SD', 'N3 ', 'N3 SD', 'N4', 'N4 SD', 'T1', 'T1 SD', 'LSC', \n",
    "    'L1', 'L2', 'L3', 'T2', 'T3', 'T4', 'C1', 'C2', 'Density', 'ClsCoef', \n",
    "    'Hubs', 'HubsSD', 'Rate', 'Filepath', 'Testpath', 'Train', 'Test']\n",
    "new_names_map = {df_cm.columns[i]:COL_NAMES[i] for i in range(len(COL_NAMES))}\n",
    "df_cm = df_cm.rename(new_names_map, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clean score\n",
    "def update_score(df_score, rate, df_cm):\n",
    "    for i in range(df_score.shape[0]):\n",
    "        data = df_score.loc[i, 'data']\n",
    "        train = df_score.loc[i, 'train']\n",
    "        test = df_score.loc[i, 'test']\n",
    "        idx = df_cm[(df_cm['Data'] == data) & (df_cm['Rate'] == rate)].index\n",
    "        df_cm.loc[idx, 'Train'] = train\n",
    "        df_cm.loc[idx, 'Test'] = test    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('Running on CPU!')\n",
    "\n",
    "HIDDEN_LAYER = 128\n",
    "LR = 0.001  # Learning rate.\n",
    "MAX_EPOCHS = 400  # Number of iteration for training.\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(X, y, batch_size=BATCH_SIZE, shuffle=True):\n",
    "    dataset = TensorDataset(torch.from_numpy(X).type(torch.float32),\n",
    "                                  torch.from_numpy(y).type(torch.int64))\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clean score\n",
    "df_score_clean = pd.read_csv(os.path.join(PATH_ROOT, 'results', 'synth_clean_score.csv'))\n",
    "update_score(df_score_clean, 0, df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_output = os.path.join(PATH_ROOT, 'results')\n",
    "path_model = os.path.join(path_output, 'torch')\n",
    "create_dir(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATES = [f'{r:.2f}' for r in np.arange(0.05, 0.41, 0.05)]\n",
    "print(RATES)\n",
    "postfix_torch = '_SimpleNN.torch'\n",
    "\n",
    "for rate in RATES:\n",
    "    print(f'Current poison rate: {rate}...')\n",
    "    path_score = os.path.join(PATH_ROOT, 'results', f'synth_rand_{rate}_score.csv')\n",
    "    if os.path.exists(path_score):\n",
    "        df_score = pd.read_csv(path_score)\n",
    "        update_score(df_score, rate, df_cm)\n",
    "    else:\n",
    "        acc_train = []\n",
    "        acc_test = []\n",
    "        datanames = []\n",
    "\n",
    "        for i in df_cm[df_cm['Rate'] == float(rate)].index:\n",
    "            dataname = df_cm.iloc[i]['Data']\n",
    "            datanames.append(dataname)\n",
    "\n",
    "            path_train = os.path.join(PATH_ROOT, df_cm.iloc[i]['Filepath'])\n",
    "            path_test = os.path.join(PATH_ROOT, df_cm.iloc[i]['Testpath'])\n",
    "\n",
    "            X_po, y_po, _ = open_csv(path_train)\n",
    "            X_test, y_test, _ = open_csv(path_test)\n",
    "            n_features = X_po.shape[1]\n",
    "\n",
    "            dataloader_poison = get_dataloader(X_po, y_po, shuffle=True)\n",
    "            dataloader_test = get_dataloader(X_test, y_test, shuffle=False)\n",
    "\n",
    "            model = SimpleModel(n_features, hidden_dim=HIDDEN_LAYER, output_dim=2).to(device)\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.8)\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "            dataname_poison = '{}_nn_rand_{}{}'.format(dataname, rate, postfix_torch)\n",
    "            _path_model = os.path.join(path_model, dataname_poison)\n",
    "            if os.path.exists(_path_model):\n",
    "                model.load_state_dict(torch.load(_path_model, map_location=device))\n",
    "            else:\n",
    "                train_model(model, dataloader_poison, optimizer, loss_fn, device, MAX_EPOCHS)\n",
    "                torch.save(model.state_dict(), _path_model)\n",
    "\n",
    "            acc_po, _ = evaluate(dataloader_poison, model, loss_fn, device)\n",
    "            acc_te, _ = evaluate(dataloader_test, model, loss_fn, device)\n",
    "            acc_train.append(acc_po)\n",
    "            acc_test.append(acc_te)\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print(f'[{dataname}] Acc train: {acc_po*100:.2f} test: {acc_te*100:.2f}')\n",
    "        results = {\n",
    "            'data': datanames,\n",
    "            'train': acc_train,\n",
    "            'test': acc_test,\n",
    "        }\n",
    "        df_score = pd.DataFrame(results)\n",
    "        df_score.to_csv(path_score, index=False)\n",
    "        update_score(df_score, float(rate), df_cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm[df_cm['Train'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm.to_csv(os.path.join(PATH_ROOT, 'results', 'synth_cmeasures_nn_rand.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8bcff36e631da1ef6cb25b63542a3f56d2322f7e3d69a7432caaf86f390cdb5a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('torch': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
